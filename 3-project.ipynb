{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview:\n",
    "\n",
    "The aim of this project is to develop a model that can predict customer churn in the telecom industry. The dataset used in this project contains information about customers' demographic information, service usage, and their churn status. We will use a Random Forest classifier to train our model, and use cross-validation to select the best hyperparameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('customer_churn.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "df.dropna(inplace=True)  # Drop rows with missing values\n",
    "X = df.drop('Churn', axis=1)  # Independent variables\n",
    "y = df['Churn']  # Dependent variable\n",
    "X = pd.get_dummies(X)  # One-hot encoding\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split the dataset\n",
    "\n",
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier()  # Instantiate the classifier\n",
    "rfc.fit(X_train, y_train)  # Fit the classifier on the training data\n",
    "y_pred = rfc.predict(X_test)  # Predict the labels for the test data\n",
    "\n",
    "# Cross-Validation\n",
    "scores = cross_val_score(rfc, X_train, y_train, cv=10)  # Perform 10-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Score:\", scores.mean())\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first load the dataset and perform data preprocessing by dropping rows with missing values, one-hot encoding the categorical features, and splitting the dataset into training and testing sets. We then instantiate a Random Forest classifier and fit it on the training data.\n",
    "\n",
    "Next, we use cross-validation to evaluate the performance of the model by performing 10-fold cross-validation and printing the average score. We then use grid search to tune the hyperparameters of the model, including the number of decision trees, maximum depth, minimum number of samples required to split an internal node, and minimum number of samples required to be at a leaf node. We print the best parameters selected by grid search.\n",
    "\n",
    "Finally, we evaluate the performance of the model on the test dataset using metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Overall, this code demonstrates how cross-validation can be used to select the best hyperparameters for a machine learning model, in this case a Random Forest classifier used to predict customer churn in the telecom industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
