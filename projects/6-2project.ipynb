{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Project 2: Convolutional Neural Networks (CNNs) in Medical Image Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business understanding – A medical research institute wants to develop an automated system to detect lung cancer in CT scans.\n",
    "\n",
    "Data understanding – The institute has a dataset of CT scans labeled as either cancerous or non-cancerous.\n",
    "\n",
    "Data preparation – We will preprocess the data by normalizing the pixel values and resizing the images to a uniform size. We will also split the data into training, validation, and test sets.\n",
    "\n",
    "Modeling – We will apply a CNN to the image dataset to classify the CT scans as cancerous or non-cancerous. We will experiment with different CNN architectures and hyperparameters to optimize the model's performance.\n",
    "\n",
    "Evaluation – We will evaluate the CNN model's performance using metrics such as accuracy, precision, recall, and F1-score. We will also compare the CNN model's performance to other image classification algorithms such as SVMs and decision trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "\n",
    "In this step, we will preprocess the data by normalizing the pixel values and resizing the images to a uniform size. We will also split the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and pre-process the data\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data directories\n",
    "train_dir = 'lung_cancer/train'\n",
    "val_dir = 'lung_cancer/val'\n",
    "test_dir = 'lung_cancer/test'\n",
    "\n",
    "# Set the target image size and batch size\n",
    "img_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "# Define the data generators with data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "# Define the data generator without data augmentation for validation and test data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n",
    "test_generator = val_datagen.flow_from_directory(test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:\n",
    "\n",
    "In this step, we will apply a CNN to the image dataset to classify the CT scans as cancerous or non-cancerous. We will experiment with different CNN architectures and hyperparameters to optimize the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=20, validation_data=val_generator, validation_steps=len(val_generator))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "\n",
    "In this step, we will evaluate the CNN model's performance using metrics such as accuracy, precision, recall, and F1-score. We will also compare the CNN model's performance to other image classification algorithms such as SVMs and decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(test_generator)\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "acc = accuracy_score(test_generator.classes, predictions)\n",
    "prec = precision_score(test_generator.classes, predictions)\n",
    "rec = recall_score(test_generator.classes, predictions)\n",
    "f1 = f1_score(test_generator.classes, predictions)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Precision:', prec)\n",
    "print('Recall:', rec)\n",
    "print('F1-score:', f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
