{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Step 1: Business Understanding\n",
    "# The business requires an image recognition model to detect and classify objects for autonomous vehicle navigation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Understanding\n",
    "# Download and extract the BDD100K dataset\n",
    "dataset_url = \"https://bdd-data.berkeley.edu/api/v1/full/compressed\"\n",
    "dataset_path = \"/data/\"\n",
    "zip_file_path = os.path.join(dataset_path, \"bdd100k.zip\")\n",
    "\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset zip file\n",
    "urllib.request.urlretrieve(dataset_url, zip_file_path)\n",
    "\n",
    "# Extract the dataset zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_path)\n",
    "\n",
    "# Define the paths to the dataset\n",
    "train_data_dir = os.path.join(dataset_path, \"bdd100k/images/100k/train\")\n",
    "valid_data_dir = os.path.join(dataset_path, \"bdd100k/images/100k/val\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Preparation\n",
    "# Set hyperparameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Modeling\n",
    "# Define and compile the deep learning model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Training\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluation\n",
    "# Evaluate the model on the test set if available or perform cross-validation\n",
    "\n",
    "# Save the model for future use\n",
    "model.save('/path/to/saved_model')\n",
    "\n",
    "# Clean up the downloaded dataset\n",
    "shutil.rmtree(dataset_path)\n",
    "os.remove(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Step 1: Business Understanding\n",
    "# The business requires an image recognition model to detect and classify objects for autonomous vehicle navigation.\n",
    "\n",
    "# Step 2: Data Understanding\n",
    "# Assuming we have a dataset with images of various objects and corresponding labels.\n",
    "\n",
    "# Step 3: Data Preparation\n",
    "# Define the paths to the dataset and split it into training and validation sets\n",
    "dataset_path = '/path/to/dataset'\n",
    "train_data_dir = dataset_path + '/train'\n",
    "valid_data_dir = dataset_path + '/valid'\n",
    "\n",
    "# Set hyperparameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Step 4: Modeling\n",
    "# Define and compile the deep learning model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 5: Model Training\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Step 6: Evaluation\n",
    "# Evaluate the model on the test set if available or perform cross-validation\n",
    "\n",
    "# Save the model for future use\n",
    "model.save('/path/to/saved_model')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we use TensorFlow and Keras to create a Convolutional Neural Network (CNN) model. We define the model architecture with convolutional layers, pooling layers, and fully connected layers. The data is prepared using data augmentation and normalization techniques. We compile the model with an optimizer and loss function. The model is then trained using the training generator and evaluated on the validation set. Finally, the trained model is saved for future use.\n",
    "\n",
    "Note: The code assumes that you have a directory structure with separate folders for training and validation data, where each folder contains subfolders for each class of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
